name: Cache and Update Package References

on:
  push:
    paths:
      - 'packages/**'
      - 'submods/**'
  pull_request:
    paths:
      - 'packages/**'
      - 'submods/**'
  workflow_dispatch:

jobs:
  build-and-cache:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          submodules: recursive
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          registry-url: 'https://registry.npmjs.org'
      
      - name: Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: 8
          run_install: false
      
      - name: Get pnpm store directory
        id: pnpm-cache
        shell: bash
        run: |
          echo "STORE_PATH=$(pnpm store path)" >> $GITHUB_OUTPUT
      
      - name: Setup pnpm cache
        uses: actions/cache@v4
        with:
          path: ${{ steps.pnpm-cache.outputs.STORE_PATH }}
          key: ${{ runner.os }}-pnpm-store-${{ hashFiles('**/pnpm-lock.yaml') }}
          restore-keys: |
            ${{ runner.os }}-pnpm-store-
      
      - name: Install dependencies
        run: pnpm install
      
      # Download the previous package hashes if available
      - name: Download previous hashes
        uses: actions/cache/restore@v4
        id: prev-hashes-cache
        with:
          path: .package-hashes/previous-hashes.txt
          key: package-hashes-${{ github.ref_name }}
          restore-keys: |
            package-hashes-

      - name: Generate package hashes
        id: package-hashes
        run: |
          mkdir -p .package-hashes

          # Create an empty file for comparing later if it doesn't exist
          if [ ! -f .package-hashes/previous-hashes.txt ]; then
            touch .package-hashes/previous-hashes.txt
          fi

          # Process submodules if needed
          for pkg_dir in $(find ./submods -type f -name "package.json" -exec dirname {} \; | grep -v "node_modules"); do
            pkg_name=$(jq -r '.name // basename($(dirname {}))' "$pkg_dir/package.json")
            if [ "$pkg_name" != "null" ]; then
              pkg_hash=$(find "$pkg_dir" -type f -not -path "*/node_modules/*" -not -path "*/dist/*" | sort | xargs cat 2>/dev/null | sha256sum | cut -d ' ' -f 1 | cut -c 1-12)
              echo "$pkg_name=$pkg_hash" >> .package-hashes/hashes.txt
              echo "Generated hash for $pkg_name: $pkg_hash"
            fi
          done

          # Process each package directory
          for pkg_dir in $(find ./packages -type f -name "package.json" -exec dirname {} \;); do
            pkg_name=$(jq -r .name "$pkg_dir/package.json")
            pkg_hash=$(find "$pkg_dir" -type f -not -path "*/node_modules/*" -not -path "*/dist/*" | sort | xargs cat 2>/dev/null | sha256sum | cut -d ' ' -f 1 | cut -c 1-12)
            echo "$pkg_name=$pkg_hash" >> .package-hashes/hashes.txt
            echo "Generated hash for $pkg_name: $pkg_hash"
          done

          # Calculate which packages have changed
          echo "# Changed packages detected:" > .package-hashes/changed-packages.txt
          while IFS= read -r line; do
            pkg_name=$(echo "$line" | cut -d '=' -f 1)
            pkg_hash=$(echo "$line" | cut -d '=' -f 2)

            # Look for this package in the previous hashes
            prev_hash=$(grep "^$pkg_name=" .package-hashes/previous-hashes.txt | cut -d '=' -f 2)

            if [ -z "$prev_hash" ] || [ "$prev_hash" != "$pkg_hash" ]; then
              # Package is new or has changed
              echo "$pkg_name" >> .package-hashes/changed-packages.txt
              echo "Package changed: $pkg_name (old hash: $prev_hash, new hash: $pkg_hash)"
            fi
          done < .package-hashes/hashes.txt

          # Save current hashes for future runs
          cp .package-hashes/hashes.txt .package-hashes/previous-hashes.txt

          echo "All package hashes:"
          cat .package-hashes/hashes.txt

          echo "Changed packages:"
          cat .package-hashes/changed-packages.txt
      
      - name: Check cache for packages
        id: packages-cache
        uses: actions/cache@v4
        with:
          path: .package-cache
          key: ${{ runner.os }}-packages-${{ hashFiles('.package-hashes/hashes.txt') }}
          restore-keys: |
            ${{ runner.os }}-packages-
      
      - name: Build packages
        if: steps.packages-cache.outputs.cache-hit != 'true'
        run: |
          mkdir -p .package-cache

          # Check if any packages from js-sdk need to be rebuilt
          js_sdk_needs_rebuild=false
          upload_service_needs_rebuild=false

          # Check changed packages to see if they're from submods
          while IFS= read -r line; do
            # Skip comment lines
            if [[ "$line" =~ ^#.* ]]; then
              continue
            fi

            # Skip empty lines
            if [ -z "$line" ]; then
              continue
            fi

            pkg_name="$line"

            # Find the package directory
            pkg_dir=$(find ./submods -path "*/node_modules" -prune -o -name "package.json" -exec grep -l "\"name\": \"$pkg_name\"" {} \; | head -n 1 | xargs dirname 2>/dev/null)

            if [ -n "$pkg_dir" ]; then
              if [[ "$pkg_dir" =~ "submods/js-sdk" ]]; then
                echo "Package $pkg_name from js-sdk needs rebuild"
                js_sdk_needs_rebuild=true
              elif [[ "$pkg_dir" =~ "submods/upload-service" ]]; then
                echo "Package $pkg_name from upload-service needs rebuild"
                upload_service_needs_rebuild=true
              fi

              # If both types need rebuilding, we can stop checking
              if $js_sdk_needs_rebuild && $upload_service_needs_rebuild; then
                break
              fi
            fi
          done < .package-hashes/changed-packages.txt

          # Build js-sdk if needed
          if $js_sdk_needs_rebuild; then
            echo "Building js-sdk packages..."
            cd "$GITHUB_WORKSPACE/submods/js-sdk"
            yarn install
            yarn build
            cd "$GITHUB_WORKSPACE"
          else
            echo "Skipping js-sdk build - no changes detected"
          fi

          # Build upload-service if needed
          if $upload_service_needs_rebuild; then
            echo "Building upload-service packages..."
            cd "$GITHUB_WORKSPACE/submods/upload-service"
            pnpm install
            pnpm nx run-many -t build
            cd "$GITHUB_WORKSPACE"
          else
            echo "Skipping upload-service build - no changes detected"
          fi

          # Pack changed packages and ensure all packages have cache entries
          echo "Packing changed packages..."

          # Create a list of packages that have already been cached
          CACHED_PKGS=()
          if [ -d "$GITHUB_WORKSPACE/.package-cache" ]; then
            for cached_file in "$GITHUB_WORKSPACE/.package-cache"/*.tgz; do
              if [ -f "$cached_file" ]; then
                filename=$(basename "$cached_file")
                cached_pkg=$(echo "$filename" | sed -E 's/(.+)-[a-f0-9]{12}\.tgz/\1/')
                CACHED_PKGS+=("$cached_pkg")
              fi
            done
          fi

          # First build and pack changed packages
          while IFS= read -r line; do
            # Skip comment lines
            if [[ "$line" =~ ^#.* ]]; then
              continue
            fi

            # Skip empty lines
            if [ -z "$line" ]; then
              continue
            fi

            pkg_name="$line"

            # Get hash for this package
            pkg_hash=$(grep "^$pkg_name=" .package-hashes/hashes.txt | cut -d '=' -f 2)

            # Find the package directory
            pkg_dir=$(find ./packages ./submods -path "*/node_modules" -prune -o -name "package.json" -exec grep -l "\"name\": \"$pkg_name\"" {} \; | head -n 1 | xargs dirname)

            if [ -n "$pkg_dir" ]; then
              echo "Processing changed package: $pkg_name from $pkg_dir"

              # Navigate to package directory
              cd "$pkg_dir"

              # Build local packages if needed (not in submods or already built)
              if [[ ! "$pkg_dir" =~ "submods/js-sdk" ]] && [[ ! "$pkg_dir" =~ "submods/upload-service" ]] && grep -q "\"build\"" package.json; then
                echo "Running build script for $pkg_name"
                pnpm run build
              fi

              # Pack the package
              echo "Packing $pkg_name"
              if [[ "$pkg_dir" =~ "submods/js-sdk" ]]; then
                pkg_file=$(yarn pack | grep -o '[^/]*\.tgz' | tail -n 1)
              else
                pkg_file=$(npm pack | tail -n 1)
              fi

              # Move the package to the cache directory with a predictable name
              mv "$pkg_file" "$GITHUB_WORKSPACE/.package-cache/${pkg_name}-${pkg_hash}.tgz"

              # Add to the list of cached packages
              CACHED_PKGS+=("$pkg_name")

              # Return to workspace root
              cd "$GITHUB_WORKSPACE"
            else
              echo "Could not find directory for package: $pkg_name"
            fi
          done < .package-hashes/changed-packages.txt

          # Then pack any packages that aren't cached yet
          echo "Checking for uncached packages..."
          while IFS= read -r line; do
            pkg_name=$(echo "$line" | cut -d '=' -f 1)
            pkg_hash=$(echo "$line" | cut -d '=' -f 2)

            # Skip if already processed
            if [[ " ${CACHED_PKGS[*]} " == *" $pkg_name "* ]]; then
              echo "Package $pkg_name already processed - skipping"
              continue
            fi

            # Skip if package file already exists in cache
            if [ -f "$GITHUB_WORKSPACE/.package-cache/${pkg_name}-${pkg_hash}.tgz" ]; then
              echo "Package $pkg_name already exists in cache - skipping"
              CACHED_PKGS+=("$pkg_name")
              continue
            fi

            # Find the package directory
            pkg_dir=$(find ./packages ./submods -path "*/node_modules" -prune -o -name "package.json" -exec grep -l "\"name\": \"$pkg_name\"" {} \; | head -n 1 | xargs dirname)

            if [ -n "$pkg_dir" ]; then
              echo "Processing uncached package: $pkg_name from $pkg_dir"

              # Navigate to package directory
              cd "$pkg_dir"

              # Pack the package
              echo "Packing $pkg_name"
              if [[ "$pkg_dir" =~ "submods/js-sdk" ]]; then
                pkg_file=$(yarn pack | grep -o '[^/]*\.tgz' | tail -n 1)
              else
                pkg_file=$(npm pack | tail -n 1)
              fi

              # Move the package to the cache directory with a predictable name
              mv "$pkg_file" "$GITHUB_WORKSPACE/.package-cache/${pkg_name}-${pkg_hash}.tgz"

              # Return to workspace root
              cd "$GITHUB_WORKSPACE"
            else
              echo "Could not find directory for package: $pkg_name"
            fi
          done < .package-hashes/hashes.txt
      
      - name: Upload package cache as artifact
        uses: actions/upload-artifact@v4
        with:
          name: npm-packages
          path: .package-cache/*.tgz
          retention-days: 30
      
      - name: Generate package urls json
        run: |
          # Get the run ID to create more stable URLs
          RUN_ID=${{ github.run_id }}
          REPO="${{ github.repository }}"

          echo "{" > package-urls.json
          comma=""
          for pkg_file in .package-cache/*.tgz; do
            if [ -f "$pkg_file" ]; then
              filename=$(basename "$pkg_file")
              pkg_name=$(echo "$filename" | sed -E 's/(.+)-[a-f0-9]{12}\.tgz/\1/')

              # Format: https://github.com/OWNER/REPO/suites/RUN_ID/artifacts/ARTIFACT_ID
              # Using a placeholder that will be filled by the use-cached-packages.yml workflow
              echo "$comma  \"$pkg_name\": \"gh+https://github.com/${REPO}/actions/runs/${RUN_ID}#${filename}\"" >> package-urls.json
              comma=","
            fi
          done
          echo "}" >> package-urls.json
      
      - name: Upload package urls
        uses: actions/upload-artifact@v4
        with:
          name: package-urls
          path: package-urls.json
          retention-days: 30

      # Save package hashes for future runs
      - name: Save package hashes
        uses: actions/cache/save@v4
        with:
          path: .package-hashes/previous-hashes.txt
          key: package-hashes-${{ github.ref_name }}

  update-dependencies:
    needs: build-and-cache
    runs-on: ubuntu-latest
    permissions:
      contents: write
      pull-requests: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          submodules: recursive

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: 8
          run_install: false

      - name: Download package-urls artifact
        uses: actions/download-artifact@v3
        with:
          name: package-urls
          path: .package-info

      - name: Download npm-packages artifact
        uses: actions/download-artifact@v3
        with:
          name: npm-packages
          path: .package-cache

      - name: List downloaded packages
        run: ls -la .package-cache

      - name: Update package URLs with local paths
        if: success()
        run: |
          if [ ! -f .package-info/package-urls.json ]; then
            echo "package-urls.json not found, skipping dependency updates"
            exit 0
          fi

          # Create a modified package-urls.json that points to local files
          jq '
            to_entries |
            map(
              .value |=
              sub("gh\\+https://github.com/[^#]+#"; "file:.package-cache/")
            ) |
            from_entries
          ' .package-info/package-urls.json > .package-info/local-urls.json

          cat .package-info/local-urls.json

      - name: Update package.json files
        if: success()
        run: |
          # Process each package.json file in the repository
          find . -name "package.json" -not -path "*/node_modules/*" -not -path "*/dist/*" | while read -r pkg_file; do
            echo "Processing $pkg_file"

            # Create a temporary file for the updated package.json
            temp_file=$(mktemp)

            # Use jq to update dependencies, devDependencies, and peerDependencies
            jq --slurpfile urls .package-info/local-urls.json '
              . as $pkg |
              $urls[0] as $url_map |

              # Function to process each dependency section
              def process_deps($deps):
                if $deps then
                  reduce (keys_unsorted[]) as $key ($deps;
                    if .[$key] | startswith("link:") and ($key | IN($url_map|keys[])) then
                      .[$key] = $url_map[$key]
                    else
                      .
                    end
                  )
                else
                  null
                end;

              # Apply to all dependency sections
              .dependencies = process_deps(.dependencies) |
              .devDependencies = process_deps(.devDependencies) |
              .peerDependencies = process_deps(.peerDependencies)
            ' "$pkg_file" > "$temp_file"

            # Replace the original file with the updated one
            mv "$temp_file" "$pkg_file"
          done

      - name: Install dependencies with updated references
        run: pnpm install

      - name: Prepare changes
        id: prepare-changes
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add -A

          # Check if there are any changes to commit
          if git diff --quiet && git diff --staged --quiet; then
            echo "No changes to commit"
            echo "has_changes=false" >> $GITHUB_OUTPUT
          else
            echo "has_changes=true" >> $GITHUB_OUTPUT
          fi

          # Check if this is a PR
          if [[ "${{ github.event_name }}" == "pull_request" ]]; then
            echo "is_pr=true" >> $GITHUB_OUTPUT
            echo "pr_number=${{ github.event.pull_request.number }}" >> $GITHUB_OUTPUT
            echo "pr_head_ref=${{ github.head_ref }}" >> $GITHUB_OUTPUT
          else
            echo "is_pr=false" >> $GITHUB_OUTPUT
          fi

      # Handling changes for a PR
      - name: Create build PR for pull request
        if: steps.prepare-changes.outputs.has_changes == 'true' && steps.prepare-changes.outputs.is_pr == 'true'
        run: |
          PR_NUMBER="${{ steps.prepare-changes.outputs.pr_number }}"
          ORIGINAL_BRANCH="${{ steps.prepare-changes.outputs.pr_head_ref }}"
          BUILD_BRANCH="build-packages-for-pr-${PR_NUMBER}"

          # Create a new branch for the build changes
          git checkout -b "$BUILD_BRANCH"

          # Commit changes
          git commit -m "Update package references to use cached builds for PR #${PR_NUMBER} [skip ci]"

          # Push the branch
          git push -u origin "$BUILD_BRANCH"

          # Create a PR targeting the original branch with auto-merge enabled if possible
          PR_URL=$(gh pr create \
            --title "Build packages for PR #${PR_NUMBER}" \
            --body "This PR updates package references to use pre-built packages from GitHub Actions artifacts.

            Targeting PR #${PR_NUMBER}

            This PR should be merged before the original PR to ensure the build includes the cached packages.

            **⚠️ Important:**
            1. After merging this PR, you should run the build-and-deploy workflow manually on your feature branch
            2. Verify the build passes with the cached packages before merging your feature PR

            To trigger the build workflow manually:
            \`\`\`
            gh workflow run build-and-deploy.yml -r $(git rev-parse HEAD) --repo ${{ github.repository }}
            \`\`\`" \
            --base "$ORIGINAL_BRANCH")

          echo "Created PR: $PR_URL"

          # Try to enable auto-merge if repository settings allow it
          PR_ID=$(echo $PR_URL | grep -o '[0-9]*$')
          if [ -n "$PR_ID" ]; then
            echo "Attempting to enable auto-merge for PR #$PR_ID"
            gh pr merge $PR_ID --auto --merge || echo "Auto-merge could not be enabled (requires admin permissions or branch protection settings)"
          fi
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      # Handling changes for direct push to a branch
      - name: Push changes directly
        id: push-changes
        if: steps.prepare-changes.outputs.has_changes == 'true' && steps.prepare-changes.outputs.is_pr == 'false'
        run: |
          git commit -m "Update package references to use cached builds"
          git push origin HEAD
          echo "pushed=true" >> $GITHUB_OUTPUT
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      # For direct pushes to main branches, trigger the build-and-deploy workflow
      - name: Trigger build and deploy
        if: >-
          steps.push-changes.outputs.pushed == 'true' &&
          (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/develop')
        run: |
          gh workflow run build-and-deploy.yml -r $(git rev-parse HEAD)
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}